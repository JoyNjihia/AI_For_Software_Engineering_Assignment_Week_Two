{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOJmPTNv49374jE7ZkcGQ/l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoyNjihia/AI_For_Software_Engineering_Assignment_Week_Two/blob/main/Week2_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set up plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "class SDGDataProcessor:\n",
        "    \"\"\"\n",
        "    A class to process and analyze SDG overall scores data\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, file_path):\n",
        "        \"\"\"Initialize with file path\"\"\"\n",
        "        self.file_path = file_path\n",
        "        self.raw_data = None\n",
        "        self.cleaned_data = None\n",
        "        self.long_format_data = None\n",
        "\n",
        "    def load_data(self):\n",
        "        \"\"\"Load the CSV data\"\"\"\n",
        "        try:\n",
        "            # Read the CSV file\n",
        "            self.raw_data = pd.read_csv(self.file_path)\n",
        "            print(f\"‚úÖ Data loaded successfully: {self.raw_data.shape}\")\n",
        "            print(f\"Columns: {list(self.raw_data.columns)}\")\n",
        "            return self.raw_data\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error loading data: {e}\")\n",
        "            return None\n",
        "\n",
        "    def clean_data(self):\n",
        "        \"\"\"Clean and prepare the data\"\"\"\n",
        "        if self.raw_data is None:\n",
        "            print(\"‚ùå No data to clean. Please load data first.\")\n",
        "            return None\n",
        "\n",
        "        # Make a copy for cleaning\n",
        "        df = self.raw_data.copy()\n",
        "\n",
        "        # Check for missing values\n",
        "        print(\"\\nüîç Missing Values Check:\")\n",
        "        missing_count = df.isnull().sum().sum()\n",
        "        print(f\"Total missing values: {missing_count}\")\n",
        "\n",
        "        # Display basic info about the dataset\n",
        "        print(f\"\\nüìä Dataset Info:\")\n",
        "        print(f\"Shape: {df.shape}\")\n",
        "        print(f\"Countries: {df['Country'].nunique()}\")\n",
        "        print(f\"Years covered: 2000-2021 ({2021-2000+1} years)\")\n",
        "\n",
        "        # Identify year columns (numeric columns that aren't ISO codes)\n",
        "        year_columns = [col for col in df.columns if col not in ['ISO', 'Country']]\n",
        "        print(f\"Year columns: {year_columns}\")\n",
        "\n",
        "        # Check data types and convert year columns to numeric if needed\n",
        "        for col in year_columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "        # Store cleaned data\n",
        "        self.cleaned_data = df\n",
        "        print(\"‚úÖ Data cleaning completed!\")\n",
        "\n",
        "        return self.cleaned_data\n",
        "\n",
        "    def reshape_to_long_format(self):\n",
        "        \"\"\"Convert data from wide to long format for time series analysis\"\"\"\n",
        "        if self.cleaned_data is None:\n",
        "            print(\"‚ùå No cleaned data available. Please clean data first.\")\n",
        "            return None\n",
        "\n",
        "        # Identify year columns\n",
        "        year_columns = [col for col in self.cleaned_data.columns if col not in ['ISO', 'Country']]\n",
        "\n",
        "        # Melt the dataframe\n",
        "        long_df = pd.melt(\n",
        "            self.cleaned_data,\n",
        "            id_vars=['ISO', 'Country'],\n",
        "            value_vars=year_columns,\n",
        "            var_name='Year',\n",
        "            value_name='SDG_Score'\n",
        "        )\n",
        "\n",
        "        # Convert Year to integer\n",
        "        long_df['Year'] = long_df['Year'].astype(int)\n",
        "\n",
        "        # Sort by country and year\n",
        "        long_df = long_df.sort_values(['Country', 'Year']).reset_index(drop=True)\n",
        "\n",
        "        # Calculate year-over-year change\n",
        "        long_df['Score_Change'] = long_df.groupby('Country')['SDG_Score'].diff()\n",
        "\n",
        "        # Calculate rolling averages\n",
        "        long_df['Score_3yr_MA'] = long_df.groupby('Country')['SDG_Score'].rolling(3, min_periods=1).mean().reset_index(drop=True)\n",
        "\n",
        "        self.long_format_data = long_df\n",
        "        print(\"‚úÖ Data reshaped to long format successfully!\")\n",
        "        print(f\"Long format shape: {long_df.shape}\")\n",
        "\n",
        "        return self.long_format_data\n",
        "\n",
        "    def analyze_trends(self):\n",
        "        \"\"\"Analyze trends in SDG scores\"\"\"\n",
        "        if self.long_format_data is None:\n",
        "            print(\"‚ùå No long format data available.\")\n",
        "            return None\n",
        "\n",
        "        df = self.long_format_data.copy()\n",
        "\n",
        "        print(\"\\nüìà TREND ANALYSIS\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        # Overall statistics\n",
        "        print(f\"Average SDG Score across all countries/years: {df['SDG_Score'].mean():.2f}\")\n",
        "        print(f\"Score range: {df['SDG_Score'].min():.2f} - {df['SDG_Score'].max():.2f}\")\n",
        "\n",
        "        # Country performance in 2021 (latest year)\n",
        "        latest_year = df['Year'].max()\n",
        "        latest_scores = df[df['Year'] == latest_year].sort_values('SDG_Score', ascending=False)\n",
        "\n",
        "        print(f\"\\nüèÜ Top 10 Countries in {latest_year}:\")\n",
        "        for i, (_, row) in enumerate(latest_scores.head(10).iterrows(), 1):\n",
        "            print(f\"{i:2d}. {row['Country']}: {row['SDG_Score']:.2f}\")\n",
        "\n",
        "        print(f\"\\nüìâ Bottom 5 Countries in {latest_year}:\")\n",
        "        for i, (_, row) in enumerate(latest_scores.tail(5).iterrows(), 1):\n",
        "            print(f\"{i:2d}. {row['Country']}: {row['SDG_Score']:.2f}\")\n",
        "\n",
        "        # Calculate improvement over time (2000 vs 2021)\n",
        "        start_year = df['Year'].min()\n",
        "\n",
        "        start_scores = df[df['Year'] == start_year][['Country', 'SDG_Score']].rename(columns={'SDG_Score': 'Start_Score'})\n",
        "        end_scores = df[df['Year'] == latest_year][['Country', 'SDG_Score']].rename(columns={'SDG_Score': 'End_Score'})\n",
        "\n",
        "        improvement_df = pd.merge(start_scores, end_scores, on='Country')\n",
        "        improvement_df['Total_Improvement'] = improvement_df['End_Score'] - improvement_df['Start_Score']\n",
        "        improvement_df['Percent_Improvement'] = (improvement_df['Total_Improvement'] / improvement_df['Start_Score']) * 100\n",
        "\n",
        "        print(f\"\\nüöÄ Most Improved Countries ({start_year}-{latest_year}):\")\n",
        "        top_improved = improvement_df.sort_values('Total_Improvement', ascending=False).head(5)\n",
        "        for _, row in top_improved.iterrows():\n",
        "            print(f\"   {row['Country']}: +{row['Total_Improvement']:.2f} points ({row['Percent_Improvement']:.1f}%)\")\n",
        "\n",
        "        print(f\"\\nüìâ Countries with Declining Scores:\")\n",
        "        declined = improvement_df[improvement_df['Total_Improvement'] < 0].sort_values('Total_Improvement').head(5)\n",
        "        for _, row in declined.iterrows():\n",
        "            print(f\"   {row['Country']}: {row['Total_Improvement']:.2f} points ({row['Percent_Improvement']:.1f}%)\")\n",
        "\n",
        "        return improvement_df\n",
        "\n",
        "    def create_visualizations(self):\n",
        "        \"\"\"Create comprehensive visualizations\"\"\"\n",
        "        if self.long_format_data is None:\n",
        "            print(\"‚ùå No data available for visualization.\")\n",
        "            return None\n",
        "\n",
        "        # Set up the plotting area\n",
        "        fig = plt.figure(figsize=(20, 15))\n",
        "\n",
        "        # 1. Time series for top countries\n",
        "        plt.subplot(2, 3, 1)\n",
        "        top_countries = ['Germany', 'France', 'Japan', 'Canada', 'United Kingdom']\n",
        "        for country in top_countries:\n",
        "            if country in self.long_format_data['Country'].values:\n",
        "                country_data = self.long_format_data[self.long_format_data['Country'] == country]\n",
        "                plt.plot(country_data['Year'], country_data['SDG_Score'], marker='o', linewidth=2, label=country)\n",
        "\n",
        "        plt.title('SDG Score Trends - Top Performing Countries', fontsize=14, fontweight='bold')\n",
        "        plt.xlabel('Year')\n",
        "        plt.ylabel('SDG Score')\n",
        "        plt.legend()\n",
        "        plt.grid(True, alpha=0.3)\n",
        "\n",
        "        # 2. Emerging economies trend\n",
        "        plt.subplot(2, 3, 2)\n",
        "        emerging_countries = ['China', 'India', 'Brazil', 'Indonesia', 'South Africa']\n",
        "        for country in emerging_countries:\n",
        "            if country in self.long_format_data['Country'].values:\n",
        "                country_data = self.long_format_data[self.long_format_data['Country'] == country]\n",
        "                plt.plot(country_data['Year'], country_data['SDG_Score'], marker='s', linewidth=2, label=country)\n",
        "\n",
        "        plt.title('SDG Score Trends - Emerging Economies', fontsize=14, fontweight='bold')\n",
        "        plt.xlabel('Year')\n",
        "        plt.ylabel('SDG Score')\n",
        "        plt.legend()\n",
        "        plt.grid(True, alpha=0.3)\n",
        "\n",
        "        # 3. Score distribution in 2021\n",
        "        plt.subplot(2, 3, 3)\n",
        "        latest_year = self.long_format_data['Year'].max()\n",
        "        latest_data = self.long_format_data[self.long_format_data['Year'] == latest_year]\n",
        "        plt.hist(latest_data['SDG_Score'], bins=15, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "        plt.axvline(latest_data['SDG_Score'].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {latest_data[\"SDG_Score\"].mean():.1f}')\n",
        "        plt.title(f'SDG Score Distribution in {latest_year}', fontsize=14, fontweight='bold')\n",
        "        plt.xlabel('SDG Score')\n",
        "        plt.ylabel('Number of Countries')\n",
        "        plt.legend()\n",
        "        plt.grid(True, alpha=0.3)\n",
        "\n",
        "        # 4. Improvement heatmap\n",
        "        plt.subplot(2, 3, 4)\n",
        "\n",
        "        # Calculate 5-year improvements\n",
        "        years = [2005, 2010, 2015, 2020]\n",
        "        countries_sample = ['USA', 'CHN', 'DEU', 'JPN', 'GBR', 'FRA', 'IND', 'BRA']\n",
        "\n",
        "        improvement_matrix = []\n",
        "        for country_iso in countries_sample:\n",
        "            country_improvements = []\n",
        "            country_data = self.long_format_data[self.long_format_data['ISO'] == country_iso]\n",
        "\n",
        "            for year in years:\n",
        "                start_score = country_data[country_data['Year'] == year-5]['SDG_Score'].iloc[0] if len(country_data[country_data['Year'] == year-5]) > 0 else np.nan\n",
        "                end_score = country_data[country_data['Year'] == year]['SDG_Score'].iloc[0] if len(country_data[country_data['Year'] == year]) > 0 else np.nan\n",
        "\n",
        "                if pd.notna(start_score) and pd.notna(end_score):\n",
        "                    improvement = end_score - start_score\n",
        "                else:\n",
        "                    improvement = 0\n",
        "\n",
        "                country_improvements.append(improvement)\n",
        "            improvement_matrix.append(country_improvements)\n",
        "\n",
        "        # Create country labels\n",
        "        country_labels = [self.long_format_data[self.long_format_data['ISO'] == iso]['Country'].iloc[0] for iso in countries_sample]\n",
        "\n",
        "        sns.heatmap(improvement_matrix,\n",
        "                   xticklabels=[f'{y-5}-{y}' for y in years],\n",
        "                   yticklabels=country_labels,\n",
        "                   annot=True,\n",
        "                   fmt='.1f',\n",
        "                   cmap='RdYlGn',\n",
        "                   center=0)\n",
        "        plt.title('5-Year SDG Score Improvements', fontsize=14, fontweight='bold')\n",
        "        plt.xlabel('Time Period')\n",
        "        plt.ylabel('Country')\n",
        "\n",
        "        # 5. Regional comparison (assuming regions based on country patterns)\n",
        "        plt.subplot(2, 3, 5)\n",
        "\n",
        "        # Define regions\n",
        "        regions = {\n",
        "            'Europe': ['Germany', 'France', 'United Kingdom', 'Italy'],\n",
        "            'North America': ['United States', 'Canada'],\n",
        "            'Asia': ['Japan', 'Korea, Rep.', 'China', 'India', 'Indonesia'],\n",
        "            'Latin America': ['Brazil', 'Argentina', 'Mexico'],\n",
        "            'Other': ['Australia', 'Russian Federation', 'Saudi Arabia', 'Turkey', 'South Africa']\n",
        "        }\n",
        "\n",
        "        regional_scores = []\n",
        "        regional_labels = []\n",
        "\n",
        "        for region, countries in regions.items():\n",
        "            region_data = self.long_format_data[\n",
        "                (self.long_format_data['Country'].isin(countries)) &\n",
        "                (self.long_format_data['Year'] == latest_year)\n",
        "            ]\n",
        "            if len(region_data) > 0:\n",
        "                regional_scores.append(region_data['SDG_Score'].mean())\n",
        "                regional_labels.append(region)\n",
        "\n",
        "        bars = plt.bar(regional_labels, regional_scores, color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7'])\n",
        "        plt.title(f'Average SDG Scores by Region ({latest_year})', fontsize=14, fontweight='bold')\n",
        "        plt.ylabel('Average SDG Score')\n",
        "        plt.xticks(rotation=45)\n",
        "\n",
        "        # Add value labels on bars\n",
        "        for bar, score in zip(bars, regional_scores):\n",
        "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, f'{score:.1f}',\n",
        "                    ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "        # 6. Score volatility (standard deviation over time)\n",
        "        plt.subplot(2, 3, 6)\n",
        "        volatility_data = self.long_format_data.groupby('Country')['SDG_Score'].std().sort_values(ascending=False)\n",
        "\n",
        "        plt.barh(range(len(volatility_data.head(10))), volatility_data.head(10).values, color='coral')\n",
        "        plt.yticks(range(len(volatility_data.head(10))), volatility_data.head(10).index)\n",
        "        plt.title('Most Volatile SDG Scores (2000-2021)', fontsize=14, fontweight='bold')\n",
        "        plt.xlabel('Standard Deviation of SDG Score')\n",
        "        plt.gca().invert_yaxis()\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('sdg_comprehensive_analysis.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "        print(\"‚úÖ Visualizations created successfully!\")\n",
        "\n",
        "    def perform_clustering(self, n_clusters=4):\n",
        "        \"\"\"Perform clustering analysis to identify collaboration patterns\"\"\"\n",
        "        if self.cleaned_data is None:\n",
        "            print(\"‚ùå No cleaned data available for clustering.\")\n",
        "            return None\n",
        "\n",
        "        print(f\"\\nü§ñ CLUSTERING ANALYSIS (K-Means with {n_clusters} clusters)\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # Prepare data for clustering (use years 2015-2021 for recent patterns)\n",
        "        recent_years = [str(year) for year in range(2015, 2022)]\n",
        "        clustering_data = self.cleaned_data[['Country'] + recent_years].copy()\n",
        "\n",
        "        # Remove any rows with missing values\n",
        "        clustering_data = clustering_data.dropna()\n",
        "\n",
        "        # Prepare features (exclude country names)\n",
        "        features = clustering_data[recent_years].values\n",
        "\n",
        "        # Standardize the features\n",
        "        scaler = StandardScaler()\n",
        "        features_scaled = scaler.fit_transform(features)\n",
        "\n",
        "        # Perform K-means clustering\n",
        "        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
        "        clusters = kmeans.fit_predict(features_scaled)\n",
        "\n",
        "        # Add cluster labels to the data\n",
        "        clustering_data['Cluster'] = clusters\n",
        "\n",
        "        # Analyze clusters\n",
        "        print(\"\\nüìä Cluster Analysis:\")\n",
        "        for i in range(n_clusters):\n",
        "            cluster_countries = clustering_data[clustering_data['Cluster'] == i]['Country'].tolist()\n",
        "            cluster_scores = clustering_data[clustering_data['Cluster'] == i][recent_years].mean(axis=1)\n",
        "\n",
        "            print(f\"\\nüè∑Ô∏è  Cluster {i+1} ({len(cluster_countries)} countries):\")\n",
        "            print(f\"   Average Score Range: {cluster_scores.min():.1f} - {cluster_scores.max():.1f}\")\n",
        "            print(f\"   Countries: {', '.join(cluster_countries)}\")\n",
        "\n",
        "        # Perform PCA for visualization\n",
        "        pca = PCA(n_components=2)\n",
        "        features_pca = pca.fit_transform(features_scaled)\n",
        "\n",
        "        # Create clustering visualization\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        colors = ['red', 'blue', 'green', 'purple', 'orange', 'brown']\n",
        "\n",
        "        for i in range(n_clusters):\n",
        "            mask = clusters == i\n",
        "            plt.scatter(features_pca[mask, 0], features_pca[mask, 1],\n",
        "                       c=colors[i], label=f'Cluster {i+1}', alpha=0.7, s=100)\n",
        "\n",
        "        # Add country labels\n",
        "        for i, country in enumerate(clustering_data['Country']):\n",
        "            plt.annotate(country, (features_pca[i, 0], features_pca[i, 1]),\n",
        "                        xytext=(5, 5), textcoords='offset points', fontsize=8, alpha=0.8)\n",
        "\n",
        "        plt.title('SDG Score Clustering Analysis (2015-2021)', fontsize=16, fontweight='bold')\n",
        "        plt.xlabel(f'First Principal Component ({pca.explained_variance_ratio_[0]:.1%} variance)')\n",
        "        plt.ylabel(f'Second Principal Component ({pca.explained_variance_ratio_[1]:.1%} variance)')\n",
        "        plt.legend()\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('sdg_clustering_analysis.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "        return clustering_data\n",
        "\n",
        "    def generate_insights(self):\n",
        "        \"\"\"Generate key insights and recommendations\"\"\"\n",
        "        print(\"\\nüí° KEY INSIGHTS & RECOMMENDATIONS\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        if self.long_format_data is not None:\n",
        "            latest_year = self.long_format_data['Year'].max()\n",
        "            avg_score = self.long_format_data[self.long_format_data['Year'] == latest_year]['SDG_Score'].mean()\n",
        "\n",
        "            print(f\"1. üìä CURRENT STATE ({latest_year}):\")\n",
        "            print(f\"   ‚Ä¢ Global average SDG score: {avg_score:.1f}/100\")\n",
        "            print(f\"   ‚Ä¢ Score gap between best and worst: {self.long_format_data[self.long_format_data['Year'] == latest_year]['SDG_Score'].max() - self.long_format_data[self.long_format_data['Year'] == latest_year]['SDG_Score'].min():.1f} points\")\n",
        "\n",
        "            # Calculate overall trend\n",
        "            improvement_stats = self.long_format_data.groupby('Country')['Score_Change'].mean()\n",
        "            improving_countries = (improvement_stats > 0).sum()\n",
        "            total_countries = len(improvement_stats)\n",
        "\n",
        "            print(f\"\\n2. üìà TRENDS (2000-{latest_year}):\")\n",
        "            print(f\"   ‚Ä¢ Countries showing improvement: {improving_countries}/{total_countries} ({improving_countries/total_countries*100:.0f}%)\")\n",
        "            print(f\"   ‚Ä¢ Average yearly improvement: {improvement_stats.mean():.2f} points/year\")\n",
        "\n",
        "            print(f\"\\n3. ü§ù COLLABORATION OPPORTUNITIES:\")\n",
        "            print(f\"   ‚Ä¢ High-scoring countries (>78) could mentor lower-scoring ones\")\n",
        "            print(f\"   ‚Ä¢ Focus on countries with declining trends for targeted support\")\n",
        "            print(f\"   ‚Ä¢ Regional partnerships could leverage geographic proximity\")\n",
        "\n",
        "            print(f\"\\n4. üìã NEXT STEPS FOR SDG17 ML PROJECT:\")\n",
        "            print(f\"   ‚Ä¢ Use clustering results to identify natural partnership groups\")\n",
        "            print(f\"   ‚Ä¢ Analyze specific SDG indicators to understand improvement drivers\")\n",
        "            print(f\"   ‚Ä¢ Develop predictive models for future SDG performance\")\n",
        "            print(f\"   ‚Ä¢ Create recommendation systems for country-to-country knowledge transfer\")\n",
        "\n",
        "# Usage example and main execution\n",
        "def main():\n",
        "    \"\"\"Main function to demonstrate the SDG data processing pipeline\"\"\"\n",
        "\n",
        "    print(\"üåç SDG DATA PROCESSING & ANALYSIS PIPELINE\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Initialize the processor\n",
        "    processor = SDGDataProcessor('SDR-2022-overall-score.csv')\n",
        "\n",
        "    # Step 1: Load data\n",
        "    print(\"\\n1. Loading data...\")\n",
        "    raw_data = processor.load_data()\n",
        "\n",
        "    if raw_data is not None:\n",
        "        # Step 2: Clean data\n",
        "        print(\"\\n2. Cleaning data...\")\n",
        "        cleaned_data = processor.clean_data()\n",
        "\n",
        "        # Step 3: Reshape to long format\n",
        "        print(\"\\n3. Reshaping data...\")\n",
        "        long_data = processor.reshape_to_long_format()\n",
        "\n",
        "        # Step 4: Analyze trends\n",
        "        print(\"\\n4. Analyzing trends...\")\n",
        "        improvement_analysis = processor.analyze_trends()\n",
        "\n",
        "        # Step 5: Create visualizations\n",
        "        print(\"\\n5. Creating visualizations...\")\n",
        "        processor.create_visualizations()\n",
        "\n",
        "        # Step 6: Perform clustering\n",
        "        print(\"\\n6. Performing clustering analysis...\")\n",
        "        clustering_results = processor.perform_clustering(n_clusters=4)\n",
        "\n",
        "        # Step 7: Generate insights\n",
        "        print(\"\\n7. Generating insights...\")\n",
        "        processor.generate_insights()\n",
        "\n",
        "        # Save processed data for ML project\n",
        "        if processor.long_format_data is not None:\n",
        "            processor.long_format_data.to_csv('data/sdg_processed_data.csv', index=False)\n",
        "            print(f\"\\nüíæ Processed data saved to 'data/sdg_processed_data.csv'\")\n",
        "\n",
        "        if clustering_results is not None:\n",
        "            clustering_results.to_csv('data/sdg_clustering_results.csv', index=False)\n",
        "            print(f\"üíæ Clustering results saved to 'data/sdg_clustering_results.csv'\")\n",
        "\n",
        "    print(f\"\\n‚úÖ Analysis complete! Ready for ML modeling phase.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bdS5zYaH5ZD",
        "outputId": "dd040b0f-b32a-485c-8ca7-3aaed04dd5d5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üåç SDG DATA PROCESSING & ANALYSIS PIPELINE\n",
            "==================================================\n",
            "\n",
            "1. Loading data...\n",
            "‚ùå Error loading data: [Errno 2] No such file or directory: 'SDR-2022-overall-score.csv'\n",
            "\n",
            "‚úÖ Analysis complete! Ready for ML modeling phase.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nlEWkQ8QI1Ok"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}